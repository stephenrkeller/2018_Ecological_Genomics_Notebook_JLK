## Author: Jamie Kostyun
## Ecological Genomics:   

### Overall Description of notebook      

This notebook will document my entries throughout the semester.


### Date started: 2018-01-24  
### Date end:   (year-month-day)    

### Philosophy   
Science should be reproducible and one of the best ways to achieve this is by logging research activities in a notebook. Because science/biology has increasingly become computational, it is easier to document computational projects in an electronic form, which can be shared online through Github.    

### Helpful features of the notebook     

**It is absolutely critical for your future self and others to follow your work.**     

* The notebook is set up with a series of internal links from the table of contents.    
* All notebooks should have a table of contents which has the "Page", date, and title (information that allows the reader to understand your work).     
* Also, one of the perks of keeping all activities in a single document is that you can **search and find elements quickly**.     
* Lastly, you can share specific entries because of the three "#" automatically creates a link when the notebook renders on github.      


<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.  


### Table of contents for 60 entries (Format is *Page: Date(with year-month-day). Title*)        
* [Page 1: 2018-01-24](#id-section1). Intro to Github, RMarkdown, and UNIX command-line
* [Page 2: 2018-01-26](#id-section2). Practice with UNIX commands
* [Page 3: 2018-01-29](#id-section3). Introduction to handling RNAseq data
* [Page 4: 2018-01-31](#id-section4). Continuing with RNAseq data: filtering and mapping to reference
* [Page 5: 2018-02-05 and 2018-02-06](#id-section5). Examining SAM file and troubleshooting 
* [Page 6: 2018-02-07](#id-section6). Exploring expression differences using DESeq2
* [Page 7: 2018-02-14](#id-section7). Using DESeq2 to assess differential gene expression
* [Page 8: 2018-02-28](#id-section8). Continuing with DESEq2 and also clustering/module ID with WGCNA
* [Page 9: 2018-03-05](#id-section9). Code for Assignment 1 analysis
* [Page 10: 2018-02-26 and 2018-02-28](#id-section10). Intro to population genomics
* [Page 11: 2018-03-05](#id-section11). Continuing with working with vcf files
* [Page 12: 2018-03-07](#id-section12). Continuing with exploring allele frequencies
* [Page 13: 2018-03-19](#id-section13). Using SNP data to examine population structure
* [Page 14: 2018-03-21](#id-section14). Using Bayescan to identify loci under differential selection
* [Page 15:](#id-section15).
* [Page 16:](#id-section16).
* [Page 17:](#id-section17).
* [Page 18:](#id-section18).
* [Page 19:](#id-section19).
* [Page 20:](#id-section20).
* [Page 21:](#id-section21).
* [Page 22:](#id-section22).
* [Page 23:](#id-section23).
* [Page 24:](#id-section24).
* [Page 25:](#id-section25).
* [Page 26:](#id-section26).
* [Page 27:](#id-section27).
* [Page 28:](#id-section28).
* [Page 29:](#id-section29).
* [Page 30:](#id-section30).
* [Page 31:](#id-section31).
* [Page 32:](#id-section32).
* [Page 33:](#id-section33).
* [Page 34:](#id-section34).
* [Page 35:](#id-section35).
* [Page 36:](#id-section36).
* [Page 37:](#id-section37).
* [Page 38:](#id-section38).
* [Page 39:](#id-section39).
* [Page 40:](#id-section40).
* [Page 41:](#id-section41).
* [Page 42:](#id-section42).
* [Page 43:](#id-section43).
* [Page 44:](#id-section44).
* [Page 45:](#id-section45).
* [Page 46:](#id-section46).
* [Page 47:](#id-section47).
* [Page 48:](#id-section48).
* [Page 49:](#id-section49).
* [Page 50:](#id-section50).
* [Page 51:](#id-section51).
* [Page 52:](#id-section52).
* [Page 53:](#id-section53).
* [Page 54:](#id-section54).
* [Page 55:](#id-section55).
* [Page 56:](#id-section56).
* [Page 57:](#id-section57).
* [Page 58:](#id-section58).
* [Page 59:](#id-section59).
* [Page 60:](#id-section60).

------
<div id='id-section1'/>
### Page 1: 2018-01-24. Notes on using Github, Rmarkdown, and the UNIX command-line.

Today, we created Github repo for the course, and started the course Notebook. 

Other goals:

* publish notebook to Github
* log into UNIX server

------
<div id='id-section2'/>
### Page 2: 2018-01-26. Practice with UNIX commands. 

Today, I practiced using UNIX commands in the Terminal, including modifying files in my home directory and connecting back to the class server. I also followed the course tutorial section about editing my settings, so as to be asked if I actually want to delete files. I think this change will be very helpful!

------
<div id='id-section3'/>
### Page 3: 2018-01-29. Introduction to handling RNAseq data

Today, we started handling RNAseq data: began learning the RNA processing pipeline, how to write a bash script, and how to interpret fastq files. 

We practiced with RNAseq data from horned beetles, where different populations have diverged in their relationship b/t male body size and horn size - i.e. different thresholds. 

First, I connected to the class server and navigated to the data directory:

      cd /data/project_data/beetles/rawdata/

...from which I examined the beginning of a fastq file:

      zcat WA_PP1_F2_AGTTCC_L003_R1_001.fastq.gz | head -n4

To examine the overall/summary quality scores for all reads in this sample (Western Australia, Female2, Paired-End1), I first created a new directory in my home directory to hold working RNAseq files. Then, I used commands from FastQ to create the quality report and have it output to my new directory:

      cd ~
      mkdir 2018_clean_reads
      fastqc /data/project_data/beetles/rawdata/WA_PP1_F2_AGTTCC_L003_R1_001.fastq.gz -o .

This output included a .zip file and an .html file. Because we will be using reads from both paired-end sets, I did the same thing with the other file:

      fastqc /data/project_data/beetles/rawdata/WA_PP1_F2_AGTTCC_L003_R2_001.fastq.gz -o .

Using cyberduck, I then moved these files to a data folder on my personal computer. Next, I opend the .html files to examine the quality scores for both sets. Overall, both sets look pretty good although PE2 has more poorer quality base calls near the end of the read. Both also have residue from the random hexamer primers at the front of the read as well as some adaptor sequence near the end - both of these issues will be fixed when we trim the reads. 

------
<div id='id-section4'/> 
### Page 4: 2018-01-31. Continuing with RNAseq data: filtering and mapping to reference

Today, we continued dealing with beetle RNAseq data. After examining the overall quality with the FastQ reports, we used the program Trimmomatic to trim and filter reads. To do so, we first copied an example script for Trimmomatic from the course materials to our home directory (into myscripts directory):

      cp /data/scripts/trim_example.sh ~/myscripts/
      
We then used the program Vim to edit the example script within the command window:

      vim trim_example.sh
      
Inside the vim edit window, this is what the example script looked like:

      #!/bin/bash
        java -classpath /data/popgen/Trimmomatic-0.33/trimmomatic-0.33.jar org.usadellab.trimmomatic.TrimmomaticPE \
                -threads 1 \ 
                -phred33 \
                 /data/project_data/beetles/rawdata/WA_PP1_YOURSAMPLE_R1.fastq.gz \
                 /data/project_data/beetles/rawdata/WA_PP1_YOURSAMPLE_R2.fastq.gz \
                 ~/cleanreads/"YOURSAMPLE_R1_clean_paired.fa" \
                 ~/cleanreads/"YOURSAMPLE_R1_clean_unpaired.fa" \
                 ~/cleanreads/"YOURSAMPLE_R2_clean_paired.fa" \
                 ~/cleanreads/"YOURSAMPLE_R2_clean_unpaired.fa" \
                 ILLUMINACLIP:/data/popgen/Trimmomatic-0.33/adapters/TruSeq3-PE.fa:2:30:10 \
                 LEADING:28 \
                TRAILING:28 \
                SLIDINGWINDOW:6:28 \
                HEADCROP:12 \
                MINLEN:35 \
                
This is specifying that it's a Java based program, where to find it (in the shared class space in data/popgen), and that we'll be using it to analyze paired end data. After the -phred33 \, we specify the input files - there are two because we're doing paired end analysis. Next, it lists the output files for the cleaned/trimmed reads. Finally, it lists the steps of functions to perform on the raw reads. Here's more info on these steps:

ILLUMINACLIP: Cut adapter and other illumina-specific sequences from the read.
SLIDINGWINDOW: Perform a sliding window trimming, cutting once the average quality within the window falls below a threshold.
LEADING: Cut bases off the start of a read, if below a threshold quality
TRAILING: Cut bases off the end of a read, if below a threshold quality
CROP: Cut the read to a specified length
HEADCROP: Cut the specified number of bases from the start of the read
MINLEN: Drop the read if it is below a specified length

To edit the script in vim, need to type "i" for INSERT. After changes are complete, hit escape key to exit edit mode. To enter general commands, type ":" followed by the command. For example, ":w" means write the changes to the file, and ":q" means quit vim.

After editing, this is what my Trimmomatic script looked like:

      #!/bin/bash
        java -classpath /data/popgen/Trimmomatic-0.33/trimmomatic-0.33.jar org.usadellab.trimmomatic.TrimmomaticPE \
                      -threads 1 \
                      -phred33 \
                       /data/project_data/beetles/rawdata/WA_PP1_F2_AGTTCC_L003_R1_001.fastq.gz \
                       /data/project_data/beetles/rawdata/WA_PP1_F2_AGTTCC_L003_R2_001.fastq.gz \
                       ~/2018_clean_reads/"WA_PP1_F2_R1_clean_paired.fa" \
                       ~/2018_clean_reads/"WA_PP1_F2_R1_clean_unpaired.fa" \
                       ~/2018_clean_reads/"WA_PP1_F2_R2_clean_paired.fa" \
                       ~/2018_clean_reads/"WA_PP1_F2_R2_clean_unpaired.fa" \
                       ILLUMINACLIP:/data/popgen/Trimmomatic-0.33/adapters/TruSeq3-PE.fa:2:30:10 \
                       LEADING:28 \
                   TRAILING:28 \
                   SLIDINGWINDOW:6:28 \
                   HEADCROP:12 \
                   MINLEN:35 \

I then changed the filename, and also changed the user permissions so I could execute it. Here, r means readable, w means writeable, and x means executable:

      mv trim_example.sh trim_Fl.sh
      chmod u+x trim_Fl.sh
      
While still in the myscripts directory, I then executed the script:

      ./trim_Fl.sh 
      
Output inside terminal window:

      TrimmomaticPE: Started with arguments: -threads 1 -phred33        /data/project_data/beetles/rawdata/WA_PP1_F2_AGTTCC_L003_R1_001.fastq.gz /data/project_data/beetles/rawdata/WA_PP1_F2_AGTTCC_L003_R2_001.fastq.gz /users/j/k/jkostyun/2018_clean_reads/WA_PP1_F2_R1_clean_paired.fa /users/j/k/jkostyun/2018_clean_reads/WA_PP1_F2_R1_clean_unpaired.fa /users/j/k/jkostyun/2018_clean_reads/WA_PP1_F2_R2_clean_paired.fa /users/j/k/jkostyun/2018_clean_reads/WA_PP1_F2_R2_clean_unpaired.fa ILLUMINACLIP:/data/popgen/Trimmomatic-0.33/adapters/TruSeq3-PE.fa:2:30:10 LEADING:28 TRAILING:28 SLIDINGWINDOW:6:28 HEADCROP:12 MINLEN:35
      Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'
      ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences
      Input Read Pairs: 16000000 Both Surviving: 10714663 (66.97%) Forward Only Surviving: 2565021 (16.03%) Reverse       Only Surviving: 734046 (4.59%) Dropped: 1986270 (12.41%)
      TrimmomaticPE: Completed successfully
      
To make sure that the script actually did what we thought it was going to, we ran FastQ on the clean reads file:

      cd 2018_clean_reads
      fastqc ~/2018_clean_reads/WA_PP1_F2_R1_clean_paired.fa
      fastqc ~/2018_clean_reads/WA_PP1_F2_R2_clean_paired.fa
      
Once satisfied with the improved quality, we then started preparing to map the clean reads against the reference. The reference for O. taurus is already available in the shared course space. To first index the file (only needs to be done once), we used the program bwa:

      bwa index /data/project_data/beetles/reference/OTAU.fna
      
Then we mapped clean reads to the reference, and output (sam file).

      bwa mem /data/project_data/beetles/reference/OTAU.fna  ~/2018_clean_reads/WA_PP1_F2_R1_clean_paired.fa ~/2018_clean_reads/WA_PP1_F2_R2_clean_paired.fa > WA_PP1_F2_bwamem.sam

------
<div id='id-section5'/>
### Page 5: 2018-02-05 and 2018-02-06. Examining SAM file and troubleshooting

Today at the beginning of class, we used the -tail function to start examining our SAM file:
      
      tail -n 100 WA_PP1_F2_bwamem.sam > tail.PP1_F2.sam
      vim tail.PP1_F2.sam
      
However, when I went to examine it, it was an empty file. So was my SAM file. Clearly there was a problem with my mapping command/output, so I followed along in class using a SAM file available in the shared class space.

But now I realized that my actual SAM file was just in another folder, and the empty one was from a first attempt at mapping where I got an error message. So I moved the correct file to the correct folder. Problem solved.

After looking over the vim field, just to get a sense of what's included in a SAM file, we assessed overall mapping quality:

      samtools flagstat WA_PP1_F2_bwamem.sam
      
Output inside terminal window:

      21506273 + 0 in total (QC-passed reads + QC-failed reads)
      0 + 0 secondary
      76947 + 0 supplementary
      0 + 0 duplicates
      17749530 + 0 mapped (82.53% : N/A)
      21429326 + 0 paired in sequencing
      10714663 + 0 read1
      10714663 + 0 read2
      17100460 + 0 properly paired (79.80% : N/A)
      17369268 + 0 with itself and mate mapped
      303315 + 0 singletons (1.42% : N/A)
      183336 + 0 with mate mapped to a different chr
      151063 + 0 with mate mapped to a different chr (mapQ>=5)
      
Next we used a python script to count reads mapping to different contigs/"genes":

      python countxpression_PE.py 20 35 ~/mydata/sam/PP1_F2_countstatssummary.txt ~/mydata/sam/WA_PP1_F2_bwamem.sam
      
However, the file only contains 0 for all reads, suggesting there is something wrong with the script. Indeed, it seems that the mem function in BWA (which we used for mapping) may have somewhat different flags than the align function (which is what the script was written for).
      
------
<div id='id-section6'/>
### Page 6: 2018-02-07. Exploring expression differences using DESeq2.

Today, we continued our exploration and analysis of beetle RNAseq data. Last time, the script we were going to use to get count data didn't work on the BWA mem function. So Melissa provided an alternate file for us that used the BWA align function to get counts, and then a bash script to combine read counts from all individuals into a single file.

First, we copied the relevant files from the course space. Typically I would just use CyyberDuck, but here I tried this:

    scp jkostyun@pbio381.uvm.edu:/data/project_data/beetles/counts/* .
    
Fo this command to work, I was in the directory on my computer that I wanted to transfer the files to (indicated by the "."). This copied two files "allcountsdataRN_noIT.txt" and "cols_data_noIT.txt".

Next, we loaded the DESeq2 package in R(Studio) and started writing a script to use for differential expression analyses. 

      #set working directory
      library("DESeq2")
      library("ggplot2")

      countsTable = read.delim('allcountsdataRN_noIT.txt', header=T, stringsAsFactors = T, row.names=1)
      countData = as.matrix(countsTable)
      head(countsData)

      conds = read.delim('cols_data_noIT.txt', header=T, stringsAsFactors = T, row.names=1)
      head(conds)
      colData = as.data.frame(conds)

      ################

      dds = DESeqDataSetFromMatrix(countData = countData, colData = colData, design = ~ devstage + sex + population)
      # DEseq2 interprets models as testing differences b/t last predictor accounting for previous predictors

      dim(dds) #gives summary of input: 17483    48

      dds1 = dds[rowSums(counts(dds)) > 1]  #revises dds to exclude transcripts with 0 reads, as previous analysis        included all transcripts
      dim(dds1) #gives updated summary: 16851    48

      dds1 = DESeq(dds1, modelMatrixType = "standard") #this is the primary command to compare transcript counts

      resultsNames(dds1)
      #[1] "Intercept" "devstage_L3L_vs_AD4" "devstage_PD1_vs_AD4" "devstage_PP1_vs_AD4" "sex_M_vs_F"         
      #[6] "population_WA_vs_NC"

      res = results(dds1)  #this aggregates output of DESeq command
      res = res[order(res$padj),] #this re-orders output by adjusted p-value
      head(res)

      #log2 fold change (MAP): population WA vs NC 
      #Wald test p-value: population WA vs NC 
      #DataFrame with 6 rows and 6 columns
      # baseMean log2FoldChange     lfcSE      stat       pvalue         padj
      # <numeric>      <numeric> <numeric> <numeric>    <numeric>    <numeric>
      # OTAU008667-RA 231.87111     -0.7803753 0.1132661 -6.889755 5.588875e-12 4.220159e-08
      # OTAU012562-RA 251.77436     -0.7828048 0.1135355 -6.894800 5.394059e-12 4.220159e-08
      # OTAU011160-RA  10.24152     -1.0863185 0.1836927 -5.913781 3.343429e-09 1.470408e-05
      # OTAU012716-RA 188.87768      1.0137238 0.1721500  5.888609 3.894604e-09 1.470408e-05
      # OTAU002976-RA 998.42315     -0.6159655 0.1075972 -5.724735 1.035950e-08 3.128984e-05
      # OTAU014686-RA 603.66091     -0.8168345 0.1468336 -5.562995 2.651835e-08 6.674668e-05

      summary(res)
      # out of 16851 with nonzero total read count
      # adjusted p-value < 0.1
      # LFC > 0 (up)     : 264, 1.6% 
      # LFC < 0 (down)   : 245, 1.5% 
      # outliers [1]     : 133, 0.79% 
      # low counts [2]   : 1616, 9.6% 
      # (mean count < 1)
      # [1] see 'cooksCutoff' argument of ?results
      # [2] see 'independentFiltering' argument of ?results



------
<div id='id-section7'/>
### Page 7: 2018-02-14. Using DESeq2 to assess differential gene expression. 

Today, we continued using DESeq2 to examine differences in gene expression between beetle populations, sex, and developmental stage. We also started examining different tools for visualizing these data.

Here is the additional code:

      ###Data Visualization###

      plotMA(res, main="DESeq2", ylim=c(-2,2)) #this plots population comparison
      abline(h=c(-1,1), col="blue", lwd = 2)

      # sex effect?

      res_sex <- results(dds1, name="sex_M_vs_F", alpha=0.05) #need to rerun model above looking at sex instead of population
      plotMA(res_sex, main="DESeq2", ylim=c(-15,15))
      abline(h=c(-1,1), col="blue", lwd = 2)

      #PCA to get a global view of gene expression
      rld <- rlog(dds1, blind=FALSE) #takes a while
      data <- plotPCA(rld, intgroup=c("population","devstage","sex"), returnData=TRUE)
      percentVar <- round(100 * attr(data, "percentVar"))

      data$devstage <- factor(data$devstage, levels=c("L3L","PP1","PD1","AD4"), labels=c("L3L","PP1","PD1","AD4"))

      ggplot(data, aes(PC1, PC2, color=sex, shape=devstage)) +
        geom_point(size=4, alpha=0.85) +
        xlab(paste0("PC1: ",percentVar[1],"% variance")) +
        ylab(paste0("PC2: ",percentVar[2],"% variance")) +
        theme_minimal()

      ggplot(data, aes(PC1, PC2, color=population, shape=devstage)) +
        geom_point(size=4, alpha=0.85) +
        xlab(paste0("PC1: ",percentVar[1],"% variance")) +
        ylab(paste0("PC2: ",percentVar[2],"% variance")) +
        theme_minimal()


      #this section will make a heatmap of all the samples vs all samples

      library("RColorBrewer")
      library("pheatmap")

      sampleDists = dist(t(assay(rld)))
      sampleDistMatrix = as.matrix(sampleDists)
      rownames(sampleDistMatrix) = paste(rld$population, rld$devstage, rld$sex, sep="-")
      colnames(sampleDistMatrix) = NULL
      colors = colorRampPalette(rev(brewer.pal(9, "Blues")))(255)

      pheatmap(sampleDistMatrix, clustering_distance_rows = sampleDists, clustering_distance_cols = sampleDists, col=colors)

      #examining specific transcripts more closely

      d = plotCounts(dds1, gene="OTAU014686-RA", intgroup= (c("population", "sex", "devstage")), returnData = T)
      p = ggplot(d, aes(x=devstage, y=count, shape=sex, color=population)) + theme_minimal() +   theme(text=element_text(size=20), panel.grid.major=element_line(color="grey"))
      p = p + geom_point(position=position_jitter(w=0.3, h=0), size=3) + scale_x_discrete(limits=c("L3L","PP1","PD1","AD4"))


      ###Save outputs###

      write.csv(res, file="DGE_NCvsWA_pop.csv", row.names=T, quote=F) #this outputs results as csv file

      neglogpval = as.matrix(-log(res$pvalue))   #script for GO Mann-Whitney test requires this format
      head(neglogpval)
      res_negpval = cbind(row.names(res), neglogpval)
      colnames(res_negpval)=c("gene", "neglogpval")

      write.csv(res_negpval, file="DGE_NCvsWA_pop_neglogpval.csv.csv", row.names=F, quote=F)


Next, we started the process for GO term assignment and assessment of significant category enrichment. For this, the required files (scripts and databases) were provided to us in the shared course space. To use them, I moved them onto my computer to run in R. I also moved the DESeq2 output file into the same directory on my computer, making sure it was in the right format. 

      input="DGE_NCvsWA_pop_neglogpval.csv" # two columns of comma-separated values: gene id, continuous measure of significance. To perform standard GO enrichment analysis based on Fisher's exact test, use binary measure (0 or 1, i.e., either sgnificant or not).
      ## Make sure this is saved as Unix (LF) - open in TextWrangler, save as, change from Classic Mac to Unix (LF)!!!
      goAnnotations="gene_annotation_only.tab" # two-column, tab-delimited, one line per gene, multiple GO terms separated by semicolon. If you have multiple lines per gene, use nrify_GOtable.pl prior to running this script.
      goDatabase="go.obo" # download from http://www.geneontology.org/GO.downloads.ontology.shtml
      goDivision="BP" # either MF, or BP, or CC
      source("gomwu.functions.R")

      # Calculating stats. It takes ~3 min for MF and BP. Do not rerun it if you just want to replot the data with different cutoffs, go straight to gomwuPlot. If you change any of the numeric values below, delete the files that were generated in previos runs first.
      gomwuStats(input, goDatabase, goAnnotations, goDivision, 
      perlPath="perl", # replace with full path to perl executable if it is not in your system's PATH already
      largest=0.1,  # a GO category will not be considered if it contains more than this fraction of the total number of genes
      smallest=5,   # a GO category should contain at least this many genes to be considered
      clusterCutHeight=0.25, # threshold for merging similar (gene-sharing) terms. 
      Alternative="g" # by default the MWU test is two-tailed; specify "g" or "l" of you want to test for "greater" or "less" instead
      )


------
<div id='id-section8'/> 
### Page 8: 2018-02-21 Continuing with DESEq2 and also clustering/module ID with WGCNA

Today, we looked at differential expession among all factors by binding them into groups.

        #this creates a new column in dataset that combines the different factors
        colData$group = factor(paste0(colData$population, "-", colData$devstage, "-", colData$sex))
        head(colData)
        dds = DESeqDataSetFromMatrix(countData = countData, colData = colData, design = ~ group)
        # DEseq2 interprets models as testing differences b/t last predictor accounting for previous predictors
        dds1 = dds[rowSums(counts(dds)) > 1, ]  #revises dds to exclude transcripts with 0 reads, as previous analysis included all transcripts
        dim(dds1) #check 
        dds1 = DESeq(dds1, parallel=T) #runs on more than one processor, if computer setup to do so
        resultsNames(dds1)
        
        res_pop_PP1_F = results(dds1, contrast = list(c("groupNC.PP1.F"), c("groupWA.PP1.F")), listValues=c(1/2, -1/2), alpha=0.05) #pulling out results for a particular comparison
        res_pop_PP1_F = res_pop_PP1_F[order(res_pop_PP1_F$padj),] #order by p-value
        head(res_pop_PP1_F)

        sig_pop_PP1_F = res_pop_PP1_F[which(res_pop_PP1_F$padj <0.05), ] #pull out sig. ones, can be used to generally subset data
        dim(sig_pop_PP1_F) #check number
        
        sig_pop_PP1_F_df = as.data.frame(sig_pop_PP1_F) #turns results into dataframe to use in heatmap plot
        sig_pop_PP1_F_df$Row.names = rownames(sig_pop_PP1_F_df)
        dim(sig_pop_PP1_F_df) 
        
        genesOfInterest_pop_PP1_F = c(sig_pop_PP1_F_df$Row.names) #pulls out gene names
        length(genesOfInterest_pop_PP1_F)  #check number
        
        vsd = vst(dds1, blind=F)
        dds1$combined = factor(paste0(dds1$population, "-", dds1$devstage, "-", dds1$sex))
        dds1$combined <- factor(dds1$combined, levels=c("WA-L3L-F","WA-L3L-M","WA-PP1-F","WA-PP1-M","WA-PD1-F","WA-PD1-M","WA-AD4-F","WA-AD4-M","NC-L3L-F","NC-L3L-M","NC-PP1-F","NC-PP1-M","NC-PD1-F","NC-PD1-M","NC-AD4-F","NC-AD4-M"), labels=c("WA-L3L-F","WA-L3L-M","WA-PP1-F","WA-PP1-M","WA-PD1-F","WA-PD1-M","WA-AD4-F","WA-AD4-M","NC-L3L-F","NC-L3L-M","NC-PP1-F","NC-PP1-M","NC-PD1-F","NC-PD1-M","NC-AD4-F","NC-AD4-M"))

        baseMeanPerGrp <- sapply( levels(dds1$combined), function(lvl) rowMeans(counts(dds1,normalized=TRUE)[,dds1$combined == lvl] ) )

        head(baseMeanPerGrp)
        dim(baseMeanPerGrp)
        
        #pulls out normalized counts (mean of 3 reps) for all the sig. genes, so we can put them on the same plot
        m = baseMeanPerGrp[genesOfInterest_pop_PP1_F, c("WA-PP1-F", "WA-PP1-M", "NC-PP1-F", "NC-PP1-M")]
        mat_scaled = t(apply(m, 1, scale))
        head(mat_scaled)
        
        library("RColorBrewer")
        library("pheatmap")
        
        pheatmap(mat_scaled, labels_col=c("WA-PP1-F", "WA-PP1-M", "NC-PP1-F", "NC-PP1-M"), cluster_cols = F, cluster_rows = T)
        
        norm.counts = counts(dds1, normalized=T)
        dim(norm.counts)
        write.csv(norm.counts, file="beetle_norm_counts.csv", row.names=T, quote=F)
        
We also started examining clustering analyses with WGCNA.

        source("http://bioconductor.org/biocLite.R") 
        biocLite(c("AnnotationDbi", "impute", "GO.db", "preprocessCore")) 
        install.packages("WGCNA")
        library("WGCNA")
        
        beetData = read.csv("beetle_norm_counts.csv")
        dim(beetData)
        Head(beetData)
        names(beetData)

        bdatExpr0 = as.data.frame(t(beetData[, -c(1:1)]))
        dim(bdatExpr0)
        names(bdatExpr0) = beetData$X
        
        row.names(bdatExpr0) = names(beetData)[-c(1:1)]

        bgsg = goodSamplesGenes(bdatExpr0, verbose = 3)

        ###### Make a cluster tree to look for outliers #####
        sampleTree = hclust(dist(bdatExpr0), method="average")

        sizeGrWindow(12,9)
        par(cex= 0.6)
        par(mar=c(0,4,2,0))

        plot(sampleTree, main="Sampling clustering to detect outliers", sub="", xlab="", cex.lab=1.5, cex.axis=1.5, cex.main=2)

        ####Read in trait data #####
        btraitData = read.table("cols_data_noIT_num.txt", header=T)
        dim(btraitData)
        head(btraitData)

        ####Network construction####
        powers = c(c(1:10), seq(from=12, to=20, by=2))

        sft = pickSoftThreshold(bdatExpr0, powerVector = powers, verbose=5)
        
        ####Data visulaization####
        sizeGrWindow(9,5)
        par(mfrow = c(1,2))
        cex=0.9
        
        plot(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2], xlab="Soft threshold (power)", ylab="Scale Free Topology Model Fit, signed R^2", type="n", main=paste("Scale independence"))
        text(sft$fitIndices[,1], -sign(sft$fitIndices[,3]*sft$fitIndices[,2], labels=powers, cex=1, col="red"))
        abline(h=0.9, col="red")

        #plot mean connectivity of soft threshold power
        plot(sft$fitIndices[,1], sft$fitIndices[,5], xlab="Soft threshold (power)", ylab="Mean Connectivity", type="n", main=paste("Mean Connectivity"))
        text(sft$fitIndices[,1], sft$fitIndices[,5], labels=powers, cex=cex1, col="red")

        net = blockwiseModules(bdatExpr0, power=6, TOMType = "unsigned", minModuleSize = 30, reassignThreshold = 0, mergeCutHeight=0.25, numericLabels=T, pamRespectsDendro=F, saveTOMS=T, saveTOMFileBase="beetleTOM", verbose=3)

        sizeGrWindow(12,9)
        mergedColors = labels2colors(net$colors)
        plotDendroAndColors(net$dendrograms[[1]], mergedColors[net$blockGenes[[1]]], "Module colors", dendroLabels=F, hang=0.03, addGuide=T, guideHang=0.05)

        moduleLabels = net$colors
        moduleColors = labels2colors(net$colors)
        MEs = net$MEs
        geneTree = net$dendrograms[[1]]
        
        ######Define number of genes in samples
        nGenes = ncol(bdatExpr0)
        nSamples = nrow(bdatExpr0)

        MEs0 = moduleEigengenes(bdatExpr0, moduleColors)$eigengenes
        MEs = orderMEs(MEs0)
        moduleTraitCor = cor(MEs, btraitData, use="p")
        moduleTraitPvalue = corPvalueStudent(moduleTraitCor, nSamples)
        
        sizeGrWindow(10,6)
        textMatrix = paste(signif(moduleTraitCor, 2), "\n(", signif(moduleTraitPvalue, 1), ")", sep="")
        dim(textMatrix) = dim(moduleTraitCor)
        par(mar = c(6,8.5,3,3))
        labledHeatmap(Matrix=moduleTraitCor, xLabels=names(btraitData), yLabels=names(MEs), ySymbols = names(MEs), colorLabels=F, colors=greenWhiteRed(50), textMatrix=textMatrix, setStdMargins=F, cex.text=0.5, zlim=c(-1,1), main=paste("Module-trait relationships"))

------
<div id='id-section9'/>
### Page 9: 2018-03-05: Code for Assignment 1 analysis

Here is my code for examining DGE between North Carolina and Western Australia beetle populations:

        ######################################### Assess DGE ##################################

        setwd("~/Documents/Academic-Research/UVM/Courses/Ecological Genomics/Data/DGE/Counts")
        
        library("DESeq2")
        library("ggplot2")
        
        ### Import data ###

        countsTable = read.delim('allcountsdataRN_noIT.txt', header=T, stringsAsFactors = T, row.names=1)
        countData = as.matrix(countsTable)
        head(countData) #check
        
        conds = read.delim('cols_data_noIT.txt', header=T, stringsAsFactors = T, row.names=1)
        head(conds) #check
        colData = as.data.frame(conds)


        ### Model to compare populations, controlling for sex and dev stage ###
        
        #want to identify differences between populations, but controlling for other relevant factors
        
        dds_pop = DESeqDataSetFromMatrix(countData = countData, colData = colData, design = ~ devstage + sex + population)
        # DEseq2 interprets models as testing differences b/t last predictor accounting for previous predictors
        
        dim(dds_pop) #gives summary of input
        dds_pop1 = dds_pop[rowSums(counts(dds_pop)) > 1, ]  #revises dds to exclude transcripts with 0 reads, as previous analysis included all transcripts
        dim(dds_pop1) #gives updated summary

        dds_pop1 = DESeq(dds_pop1, parallel=T, modelMatrixType = "standard")
        
        res = results(dds_pop1)  #this aggregates output of DESeq command
        res = res[order(res$padj),] #this re-orders output by adjusted p-value
        res = res[order(res$log2FoldChange),] #this re-orders output by Fold Change
        head(res) #gives a peak at output
        
        summary(res) #default is p<0.1
        summary(res, alpha=0.05)
        
        write.csv(res, file="DGE_NCvsWA_pop.csv", row.names=T, quote=F) #this outputs results as csv file
        
        sig_res_pop = res[which(res$padj <0.05), ] #pull out sig. only
        write.csv(sig_res_pop, file="DGE_NCvsWA_pop_sig.csv", row.names=T, quote=F) 
        
        neglogpval = as.matrix(-log(res$pvalue))   #script for GO Mann-Whitney test requires this format
        res_negpval = cbind(row.names(res), neglogpval) #here using raw p-value
        colnames(res_negpval)=c("gene", "neglogpval")
        
        write.csv(res_negpval, file="DGE_NCvsWA_neglogpval.csv", row.names=F, quote=F)
        
        #MA plot to visualize global differential expression
        plotMA(res, main="NC vs. WA Global Expression Differences", alpha=0.05, ylim=c(-1.5,1.5))
        #abline(h=c(-1,1), col="blue", lwd = 2)
        
        #PCA to get a global view of gene expression patterns
        rld_pop <- rlog(dds_pop1, blind=FALSE) 
        data <- plotPCA(rld_opop, intgroup=c("population","devstage","sex"), returnData=TRUE)
        percentVar <- round(100 * attr(data, "percentVar"))
        
        ggplot(data, aes(PC1, PC2, color=population, shape=sex)) +
          geom_point(size=4, alpha=0.85) +
          xlab(paste0("PC1: ",percentVar[1],"% variance")) +
          ylab(paste0("PC2: ",percentVar[2],"% variance")) +
          theme_minimal()
        
        ggplot(data, aes(PC1, PC2, color=population, shape=devstage)) +
          geom_point(size=4, alpha=0.85) +
          xlab(paste0("PC1: ",percentVar[1],"% variance")) +
          ylab(paste0("PC2: ",percentVar[2],"% variance")) +
          theme_minimal()
        
        ggplot(data, aes(PC1, PC2, color=sex, shape=devstage)) +
          geom_point(size=4, alpha=0.85) +
          xlab(paste0("PC1: ",percentVar[1],"% variance")) +
          ylab(paste0("PC2: ",percentVar[2],"% variance")) +
          theme_minimal()


        ### Models to compare sex-specific expression across developmental stages ###
        
        #want to compare NC Female vs. WA Female and NC Male vs. WA Male
        
        colData$group = factor(paste0(colData$population, "-", colData$sex)) #creates group of population and sex, 'ignoring' dev stage
        head(colData)

        # population devstage sex ind group
        # NC_AD4_F1_         NC      AD4   F   1  NC-F
        # NC_AD4_F2_         NC      AD4   F   2  NC-F
        # NC_AD4_F3_         NC      AD4   F   3  NC-F
        # NC_AD4_M1_         NC      AD4   M   1  NC-M
        # NC_AD4_M2_         NC      AD4   M   2  NC-M
        # NC_AD4_M3_         NC      AD4   M   3  NC-M
        
        dds_sex = DESeqDataSetFromMatrix(countData = countData, colData = colData, design = ~ group)
        
        dim(dds_sex) 
        dds_sex1 = dds_sex[rowSums(counts(dds_sex)) > 1, ]  
        dim(dds_sex1) 
        
        dds_sex1 = DESeq(dds_sex1, parallel=T)
        
        resultsNames(dds_sex1)
        # [1] "Intercept" "groupNC.F" "groupNC.M" "groupWA.F" "groupWA.M"

        #For females
        res_F = results(dds_sex1, contrast = list(c("groupNC.F"), c("groupWA.F")), listValues=c(1/2, -1/2))
        res_F = res_F[order(res_F$padj),]
        head(res_F)
        
        summary(res_F)
        summary(res_F, alpha=0.05)
        
        write.csv(res_F, file="DGE_NCvsWA_F.csv", row.names=T, quote=F)
        
        sig_res_F = res_F[which(res_F$padj <0.05), ] #pull out sig. only
        write.csv(sig_res_F, file="DGE_NCvsWA_F_sig.csv", row.names=T, quote=F)

        #For males
        res_M = results(dds_sex1, contrast = list(c("groupNC.M"), c("groupWA.M")), listValues=c(1/2, -1/2))
        res_M = res_F[order(res_M$padj),]
        head(res_M)
        
        summary(res_M)
        summary(res_M, alpha=0.05)
        
        sig_res_M = res_M[which(res_M$padj <0.05), ] #pull out sig. only
        
        write.csv(res_M, file="DGE_NCvsWA_M.csv", row.names=T, quote=F)
        write.csv(sig_res_M, file="DGE_NCvsWA_M_sig.csv", row.names=T, quote=F)

        neglogpval_F = as.matrix(-log(res_F$pvalue))   #script for GO Mann-Whitney test requires this format
        res_negpval_F = cbind(row.names(res_F), neglogpval_F)
        colnames(res_negpval_F)=c("gene", "neglogpval")
        
        write.csv(res_negpval_F, file="DGE_NCvsWA_F_neglogpval.csv", row.names=F, quote=F)
        
        neglogpval_M = as.matrix(-log(res_M$pvalue))   #script for GO Mann-Whitney test requires this format
        res_negpval_M = cbind(row.names(res_M), neglogpval_M) #this uses raw p-value rather than adjusted (seems to be too restrictive for GO script)
        colnames(res_negpval_M)=c("gene", "neglogpval")
        
        write.csv(res_negpval_M, file="DGE_NCvsWA_M_neglogpval.csv", row.names=F, quote=F)

        #PCA to get a global view of gene expression
        rld_sex <- rlog(dds_sex1, blind=FALSE) 
        data <- plotPCA(rld_sex, intgroup=c("population","devstage","sex"), returnData=TRUE)
        percentVar <- round(100 * attr(data, "percentVar"))
        
        ggplot(data, aes(PC1, PC2, color=population, shape=sex)) +
          geom_point(size=4, alpha=0.85) +
          xlab(paste0("PC1: ",percentVar[1],"% variance")) +
          ylab(paste0("PC2: ",percentVar[2],"% variance")) +
          theme_minimal()
        #basically shows same patterns as above, not terribly informative

        #For heat map of within sex comparisons
        library("plyr") #for manipulating data frames
        library("dplyr")
        library("RColorBrewer")
        library("pheatmap")
        
        Pop_F_df = as.data.frame(res_F) #turns results into dataframe to use in heatmap plot
        Pop_F_df$Row.names = rownames(Pop_F_df)
        
        Pop_M_df = as.data.frame(res_M) #turns results into dataframe to use in heatmap plot
        Pop_M_df$Row.names = rownames(Pop_M_df)
        
        sig_pop_F = res_F[which(res_F$padj <0.05), ] #pull out sig. ones from F-F
        sig_pop_M = res_F[which(res_M$padj <0.05), ] #pull out sig. ones from M-M

        sig_pop_F_df = as.data.frame(sig_pop_F) #turns results into dataframe to use in heatmap plot
        sig_pop_F_df$Row.names = rownames(sig_pop_F_df)
        dim(sig_pop_F_df) 
        
        sig_pop_M_df = as.data.frame(sig_pop_M) #turns results into dataframe to use in heatmap plot
        sig_pop_M_df$Row.names = rownames(sig_pop_M_df)
        dim(sig_pop_M_df) 
        
        sig_pop_FM = rbind(sig_pop_F_df, sig_pop_M_df) #combine these into one data frame
        #sig_pop_FM1 = distinct(sig_pop_FM) #remove any duplicates
        dim(sig_pop_FM)
        
        genesOfInterest_pop_FM = c(sig_pop_FM$Row.names) #pulls out gene names
        length(genesOfInterest_pop_FM)

        vsd = vst(dds_sex1, blind=F)
        dds_sex1$combined = factor(paste0(dds_sex1$population, "-", dds_sex1$sex))
        dds_sex1$combined <- factor(dds_sex1$combined, levels=c("NC-F","NC-M","WA-F","WA-M"), labels=c("NC-F","NC-M","WA-F","WA-M"))
        
        baseMeanPerGrp <- sapply( levels(dds_sex1$combined), function(lvl) rowMeans(counts(dds_sex1,normalized=TRUE)[,dds_sex1$combined == lvl] ) )
        
        head(baseMeanPerGrp) #check
        dim(baseMeanPerGrp)

        #pulls out normalized counts (mean of 3 reps) for all the sig. genes, so we can put them on the same plot
        m = baseMeanPerGrp[genesOfInterest_pop_FM, c("NC-F","NC-M","WA-F","WA-M")]
        
        mat_scaled = t(apply(m, 1, scale))
        
        pheatmap(mat_scaled, labels_col=c("NC-F", "NC-M", "WA-F", "WA-M"), cluster_cols = F, cluster_rows = T)
        
        
        ################################# Examine GO Enrichment ###############################

        ### Mann-Whitney Tests for GO Analysis ###
        
        setwd("~/Documents/Academic-Research/UVM/Courses/Ecological Genomics/Data/DGE/Enrichment")
        library(ape)
        
        
        # Importing data:

        input="DGE_NCvsWA_neglogpval.csv" # two columns of comma-separated values: gene id, continuous measure of significance. To perform standard GO enrichment analysis based on Fisher's exact test, use binary measure (0 or 1, i.e., either sgnificant or not).
        ## Make sure this is saved as Unix (LF) - open in TextWrangler, save as, change from Classic Mac to Unix (LF)!!!
        
        input="DGE_NCvsWA_F_neglogpval.csv"
        
        input="DGE_NCvsWA_M_neglogpval.csv"
        
        goAnnotations="gene_annotation_only.tab" # two-column, tab-delimited, one line per gene, multiple GO terms separated by semicolon. If you have multiple lines per gene, use nrify_GOtable.pl prior to running this script.
        goDatabase="go.obo" # download from http://www.geneontology.org/GO.downloads.ontology.shtml
        goDivision="BP" # either MF, or BP, or CC
        source("gomwu.functions.R")

        
        # Calculating stats. It takes ~3 min for MF and BP. Do not rerun it if you just want to replot the data with different cutoffs, go straight to gomwuPlot. If you change any of the numeric values below, delete the files that were generated in previous runs first.
        gomwuStats(input, goDatabase, goAnnotations, goDivision,
                   perlPath="perl", # replace with full path to perl executable if it is not in your system's PATH already
                   largest=0.1,  # a GO category will not be considered if it contains more than this fraction of the total number of genes
                   smallest=5,   # a GO category should contain at least this many genes to be considered
                   clusterCutHeight=0.25, # threshold for merging similar (gene-sharing) terms. 
                   Alternative= "g" # by default the MWU test is two-tailed; specify "g" or "l" of you want to test for "greater" or "less" instead
        )

        quartz() #creates new window for cluster tree
        gomwuPlot(input,goAnnotations,goDivision,
                  absValue=-log(0.05,10),  # genes with the measure value exceeding this will be counted as "good genes". Specify absValue=0.5 if you are doing Fisher's exact test for standard GO enrichment.
                  level1=0.1, # FDR threshold for plotting. Specify level1=1 to plot all GO categories containing genes exceeding the absValue.
                  level2=0.05, # FDR cutoff to print in regular (not italic) font.
                  level3=0.01, # FDR cutoff to print in large bold font.
                  txtsize=1.2,    # decrease to fit more on one page, or increase (after rescaling the plot so the tree fits the text) for better "word cloud" effect
                  treeHeight=0.5, # height of the hierarchical clustering tree
                  colors=c("dodgerblue2","firebrick1","skyblue","lightcoral") # these are default colors, un-remar and change if needed
        )
        
        
------
<div id='id-section10'/>
### Page 10: 2018-02-26 and 2018-02-28: Intro to population genomics

I actually missed class this week as I was in Amherst, but here's my followup.

First, we need to convert our data in .sam format to .bam format, which is the binary version. Then we can sort it, remove unpaired reads, remove PCR duplicates, and index. Make this as a bash script called CallSNPs.sh:

        #!/bin/bash

        samtools view -@ 4 -bS WA_PP1_F1_bwamem.sam > WA_PP1_F1_bwamem.bam #convert to bam
        samtools flagstat WA_PP1_F1_bwamem.bam #gives summary
        samtools depth WA_PP1_F1_bwamem.bam #seq depth
        samtools fixmate -@ 4 WA_PP1_F1_bwamem.bam WA_PP1_F1_bwamem.fm.bam #remove unpaired
        samtools sort -@ 4 WA_PP1_F1_bwamem.fm.bam -o WA_PP1_F1_bwamem.fm.sort.bam #sort reads
        samtools rmdup WA_PP1_F1_bwamem.fm.sort.bam WA_PP1_F1_bwamem.fm.sort.rmdup.bam #remove PCR duplicates
        samtools index WA_PP1_F1_bwamem.fm.sort.bam #indexes file to easier computations
        
Once done, we want to look at our data before proceeding:

        samtools tview WA_PP1_F1_bwamem.fm.sort.bam

Next, we want to map our reads to the reference, which we do my adding to our CallSNPs.sh

        bcftools mpileup -Ou -f /data/project_data/beetles/reference/OTAU.fna ~/mydata/WA_PP1_F1_bwamem.fm.sorted.bam --threads 4 --skip-indel --annotate AD,DP | bcftools call -Ov -mv --format-fields GQ,GP > WA_PP1_F1.vcf
        

------
<div id='id-section11'/>
### Page 11: 2018-03-05: Continuing with working with vcf files

Today, we compared different methods to identify SNPs from the beetle RNAseq data.

        cd /data/project_data/beetles/snps
        
Using vcftools to process the vcf file to retain only biallelic SNPs, remove SNPs below 0.01 freq, retain only high quality SNPs, remove SNPs with >80% missing data, output heterozygosity measure:

        vcftools --vcf OTAU_2018_samtools.vcf --min-alleles 2 --max-alleles 2 --maf 0.01 --minGQ 20 --max-missing 0.8 --het --out ~/mydata/samtools0.8
        #output: Parameters as interpreted:
        	--vcf OTAU_2018_samtools.vcf
        	--maf 0.01
        	--max-alleles 2
        	--min-alleles 2
        	--minGQ 20
        	--max-missing 0.8
        	--het
        	--out /users/j/k/jkostyun/mydata/samtools0.8
        
        After filtering, kept 72 out of 72 Individuals
        Outputting Individual Heterozygosity
        After filtering, kept 117 out of a possible 611928 Sites
        Run Time = 19.00 seconds
        
Testing how this differs by changing the quality requirements:

        vcftools --vcf OTAU_2018_samtools.vcf --min-alleles 2 --max-alleles 2 --maf 0.01 --minGQ 10 --max-missing 0.8 --het --out ~/mydata/samtools0.8v2
        #output: Parameters as interpreted:
        	--vcf OTAU_2018_samtools.vcf
        	--maf 0.01
        	--max-alleles 2
        	--min-alleles 2
        	--minGQ 10
        	--max-missing 0.8
        	--het
        	--out /users/j/k/jkostyun/mydata/samtools0.8v2
        
        After filtering, kept 72 out of 72 Individuals
        Outputting Individual Heterozygosity
        After filtering, kept 83120 out of a possible 611928 Sites
        Run Time = 20.00 seconds
        
Next we examined the inbreeding coefficient as another way to assess retention of SNPs. In R:

        df=read.table("samtools0.8v2.het", header=T)
        str(df)
        #output: 
        'data.frame':	72 obs. of  5 variables:
         $ INDV   : Factor w/ 72 levels "IT_AD4_F1_","IT_AD4_F2_",..: 1 2 3 4 5 6 8 9 10 7 ...
         $ O.HOM. : int  66334 59874 69153 61780 67300 69025 64488 73824 68621 67290 ...
         $ E.HOM. : num  66365 60720 69302 61431 67564 ...
         $ N_SITES: int  70922 64890 74059 65648 72209 73834 70006 81319 75543 73303 ...
         $ F      : num  -0.00683 -0.20302 -0.03141 0.08282 -0.05684 ...
         summary(df$F)
         #output:
         Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
    -0.748830 -0.193505  0.003465 -0.015433  0.163995  0.320880 
        sd(df$F) #0.2154291
        
Back to command-line. As a class, we determined that using the read2snps method and max missing data 0.8 works best:

      vcftools --vcf OTAU_2018_reads2snps_DP10GP95.vcf --min-alleles 2 --max-alleles 2 --maf 0.01  --max-missing 0.8 --recode --out ~/mydata/OTAU_2018_reads2snps_DP10GP95_biallelic_MAF0.01_Miss0.8.vcf
      #output: Parameters as interpreted:
      	--vcf OTAU_2018_reads2snps_DP10GP95.vcf
      	--maf 0.01
      	--max-alleles 2
      	--min-alleles 2
      	--max-missing 0.8
      	--out /users/j/k/jkostyun/mydata/OTAU_2018_reads2snps_DP10GP95_biallelic_MAF0.01_Miss0.8.vcf
      	--recode
      
      After filtering, kept 72 out of 72 Individuals
      Outputting VCF file...
      After filtering, kept 133291 out of a possible 33366006 Sites
      Run Time = 89.00 seconds
      
      grep "IT" /data/project_data/beetles/metadata/cols_data.txt #find IT data
      grep "IT" /data/project_data/beetles/metadata/cols_data.txt | cut -f 1 >IT.inds #pull out IT data and create new file
      vcftools --vcf OTAU_2018_reads2snps_DP10GP95_biallelic_MAF0.01_Miss0.8.vcf.recode.vcf --keep IT.inds --freq2 --out IT
      #output: Parameters as interpreted:
        	--vcf OTAU_2018_reads2snps_DP10GP95_biallelic_MAF0.01_Miss0.8.vcf.recode.vcf
        	--keep IT.inds
        	--freq2
        	--out IT
        
        Keeping individuals in 'keep' list
        After filtering, kept 24 out of 72 Individuals
        Outputting Frequency Statistics...
        After filtering, kept 133291 out of a possible 133291 Sites
        Run Time = 2.00 seconds
        
        head IT.frq #check file
        
------
<div id='id-section12'/>
### Page 12: 2018-05-07: Continuing with exploring allele frequencies

Today, we continued exploring the beetle RNAseq data with respect to SNPs by pulling out data for the remaining populations.

        grep "NC" /data/project_data/beetles/metadata/cols_data.txt | cut -f 1 >NC.inds
        vcftools --vcf OTAU_2018_reads2snps_DP10GP95_biallelic_MAF0.01_Miss0.8.vcf.recode.vcf --keep NC.inds --freq2 --out NC
        grep "WA" /data/project_data/beetles/metadata/cols_data.txt | cut -f 1 >WA.inds
        vcftools --vcf OTAU_2018_reads2snps_DP10GP95_biallelic_MAF0.01_Miss0.8.vcf.recode.vcf --keep WA.inds --freq2 --out WA
        #want to remove SNPs that are linked, so here retaining only one SNP per 1000bp
        vcftools --vcf OTAU_2018_reads2snps_DP10GP95_biallelic_MAF0.01_Miss0.8.vcf.recode.vcf --thin 1000 --recode

After getting allele frequencies for each population separately, we visualized minor allele frequency spectrum plots in R.

        IT = read.table("IT.frq", skip=1, header=F) 
        head(IT) #check
        dim(IT) #check size
        #lists gene name, bp position of SNP in gene, how many alelles at SNP, number of alleles sampled in population, reference allele freq, minor allele freq
        
        NC = read.table("NC.frq", skip=1, header=F)
        WA = read.table("WA.frq", skip=1, header=F)
        
        #hist(IT$V6, col="red", main="MAF in IT Population", xlab="Minor Allele")
        
        IT = hist(IT$V6, plot=F)
        IT$counts = IT$counts/sum(IT$counts)
        plot(IT$counts, type="l", main="Normalized MAF in IT Population")
        
        NC = hist(NC$V6, plot=F)
        NC$counts = NC$counts/sum(NC$counts)
        plot(NC$counts, type="l", main="Normalized MAF in NC Population")
        
        WA = hist(WA$V6, plot=F)
        WA$counts = WA$counts/sum(WA$counts)
        plot(WA$counts, type="l", main="Normalized MAF in WA Population")
        
        #plot all together
        plot(IT$counts, type="l", col="red", lwd=1.5, ylim=c(0,0.5), main="Normalized MAF among Populations")
        lines(NC$counts, col="blue", lwd=1.5)
        lines(WA$counts, col="green", lwd=1.5)
        
Next we copied files for ADMIXTURE analysis to our working directories:

        cp /data/project_data/beetles/metadata/beetles.pop .
        cp /data/scripts/beetle.spid .
        cp /data/scripts/vcf2geno.sh .
        cp /data/project_data/beetles/snps/out.recode.vcf.geno .
        
And created a bash script to run ADMIXTURE for K= 1 - 10:

        vim #to create new bash script
        
This is what it looked like:   

        #!/bin/bash
        for K in {1...10}
        do
        admixture -j 4 --cv 10 ~/mydata/out.recode.vcf.geno $K | tee log${K}.out
        done
        grep "CV" log*out >chooseK.txt
        
        
        chmod u+x ADMIX.sh #to change file permissions

------
<div id='id-section13'/>
### Page 13: 2018-03-19: Using SNP data to examine population structure

Today, we continued getting our SNP data ready to use in ADMIXTURE to examine population structure. This included slightly revising our vcf2geno.sh script, which calls to the PGDSpider program to convert our SNP data in vcf format to geno format which is required by ADMIXTURE:

       vim vcf2geno.sh #to edit script to look like this:
       
        #!/bin/bash

        java -Xmx2G -jar /data/popgen/PGDSpider_2.0.9.0/PGDSpider2-cli.jar -inputfile ~/mydata/SNPs/out.recode.vcf -inputformat VCF -outputfile ~/mydata/SNPs/out.recode.vcf.geno -outputformat EIGENSOFT -spid ~/myscripts/beetle.spid
        
This output format codes SNPs as: 0=homozygous ref, 1=heterozgous, 2=homozygous derived, 9=missing data. 

Next, we slightly updated our ADMIX.sh script to make it actually run. Here, the cv refers to cross validation, where the program divides the data into n groups. It then cycles though, masking one group at a time: it trains on the 'available' data, and then tests its assignment model with the masked group. Well supported estimates of K will return lower values of cv error (i.e. the model is better at predicting the assignment of the masked group).
       
       vim ADMIX.sh   
       
       #!/bin/bash

        for K in {1..10}
        
        do
        
        admixture -j4 --cv=10 ~/mydata/SNPs/out.recode.vcf.geno $K | tee log${K}.out
        
        done
        
        grep "CV" log*out >chooseK.txt
       
The output from ADMIX.sh includes multiple types of files: .P includes allele freq for each K, .Q provides ancestry coeff for each K, and .log is logged output for each K. It then also searches within the log files to find the cv error for eack value of K, and puts this into the chooseK.txt file. Here is what that file looked like:

        cat chooseK.txt
        
        log10.out:CV error (K=10): 0.74078
        log1.out:CV error (K=1): 0.44089
        log2.out:CV error (K=2): 0.43635
        log3.out:CV error (K=3): 0.44473
        log4.out:CV error (K=4): 0.47987
        log5.out:CV error (K=5): 0.51791
        log6.out:CV error (K=6): 0.55534
        log7.out:CV error (K=7): 0.58280
        log8.out:CV error (K=8): 0.62599
        log9.out:CV error (K=9): 0.66978
        
Based on these cv errors, we want to focus on K=2 through K=4. We therefore moved the .Q files to our local computer so as to be able to visualize the data using the R package pophelper:

        install.packages(c("Cairo","ggplot2","gridExtra","gtable","tidyr","devtools"),dependencies=T)
        
However, I needed to install an earlier version of Cairo than the one that is automatically called to in the above install command, as well as install X11 to properly load the Cairo package. Once I did that, I could install and load in the pophelper package:

        devtools::install_github('royfrancis/pophelper')
        
We also moved cols_data.text, which contains metadata for all the beetle individuals, to our local computers for use in R.

        setwd("~/Documents/Academic-Research/UVM/Courses/Ecological Genomics/Data/Pop_Genomics")

        library(pophelper)
        
        admixfiles=list.files(path=("ADMIXTURE/"),full.names=T)
        admixlist=readQ(files=admixfiles,filetype="basic")
        
        # metadata: sample id and pop from beetle metadata file
        metadata=read.table("cols_data.txt",header=T)
        
        # format metadata to a data frame and ind variables as chars. for plotting
        metadata2=data.frame(sampleid=metadata[,1], population=metadata[,2])
        
        metadata2$sampleid=as.character(metadata2$sampleid)
        metadata2$population=as.character(metadata2$population)
        
        # add in the sample id to the different Q files for plotting
        if(length(unique(sapply(admixlist,nrow)))==1)
          admixlist <- lapply(admixlist,"rownames<-",metadata2$sampleid)
        
        head(admixlist[[3]]) #peak at what the ancestry assignments for K=4 look like (K=4 is in 3rd column in this datafile)
        
        p <- plotQ(admixlist[c(1,2,3)],
                   returnplot=T,exportplot=T,quiet=T,basesize=11, imgoutput="join", 
                   showyaxis=T, showticks=T, panelspacer=0.4, useindlab=F, showindlab=F, 
                   grplab=metadata2[2], grplabsize=4, linesize=1, barsize=1, pointsize=3, 
                   panelratio=c(4,1), divsize = 0.75, pointcol="white", showtitle=T, 
                   titlelab="ADMIXTURE analysis on O. tauri, SNPs thinned to 1 per kb", 
                   splab=c("K=2","K=3","K=4"), outputfilename="ADMIXTURE_Otauri",
                   imgtype="pdf",height=3,width=25)
        
        plot(p$plot[[1]])


------
<div id='id-section14'/>
### Page 14: 2018-03-21: Using Bayescan to identify loci under differential selection

Today, we discussed various approaches to identifying loci that might be under differential selection in different populations. A common way to do so is to find Fst outliers, however, Fst is also highly dependent on population structure and demographic history. We therefore used a method called Bayescan which explictly incorporates a demographic model to determine expected Fst values given that particular population structure and history (parameter beta in model). It also determines parameter alpha, which is a differentiation metric for loci which incorporates the expected values of beta. Alpha therefore approximates the amount of differentiation between populations due to selection, rather than drift/demography. Alpha values around 0 indicate neutrality, highly negative values indicate purifying or stabilizing selection (i.e. populations are more similar to one another than expected given their demographic model), and highly positive values indicate directional selection (i.e. populations are more differentiated than expected under the given demographic model).

To run Bayescan on the beetle data, we first need to convert our .vcf SNP file to the bayescan format. This can be done using PGDSpider. However, because this takes a long time, the converted file was provided to us:

        /data/project_data/beetles/snps/OTAU_2018_reads2snps_DP10GP95_biallelic_MAF01_Miss0.8.vcf.recode.vcf.bayescan
        
To actually run Bayescan, we created a bash script:

        vim #to create new, this is what it looked like:
        
        #!/bin/bash
        
        for thin in 10 20 30   #here, we are running different MCMC chains and sampling every 10, 20, or 30 values

        do
        
        bayescan /data/project_data/beetles/snps/OTAU_2018_reads2snps_DP10GP95_biallelic_MAF01_Miss0.8.vcf.recode.vcf.bayescan -od ~/mydata/SNPs -threads 4 -pr_odds 1000 -thin $thin -o $thin
        
        #the above command tells it to run Bayescan on that data file, to output to mydata/SNPs folder, to use 4 threads of computing power, to use 1000 for the prior (means the model assumes every 1 in 1000 is under selection), to use the above specified values of $thin, and to output each run to a different filename
        
        done
        
To save and exit the script:

        :w Bayescan.sh
        :q
        chmod u+x Bayescan.sh #to change file permissions
        
To then run the script, which will take a long time so we used screen:

        screen
        bash Bayescan.sh
        "control A+D" #to detach
        


------
<div id='id-section15'/>
### Page 15:
------
<div id='id-section16'/>
### Page 16:
------
<div id='id-section17'/>
### Page 17:
------
<div id='id-section18'/>
### Page 18:
------
<div id='id-section19'/>
### Page 19:
------
<div id='id-section20'/>
### Page 20:
------
<div id='id-section21'/>
### Page 21:
------
<div id='id-section22'/>
### Page 22:
------
<div id='id-section23'/>
### Page 23:
------
<div id='id-section24'/>
### Page 24:
------
<div id='id-section25'/>
### Page 25:
------
<div id='id-section26'/>
### Page 26:
------
<div id='id-section27'/>
### Page 27:
------
<div id='id-section28'/>
### Page 28:
------
<div id='id-section29'/>
### Page 29:
------
<div id='id-section30'/>
### Page 30:
------
<div id='id-section31'/>
### Page 31:
------
<div id='id-section32'/>
### Page 32:
------
<div id='id-section33'/>
### Page 33:
------
<div id='id-section34'/>
### Page 34:
------
<div id='id-section35'/>
### Page 35:
------
<div id='id-section36'/>
### Page 36:
------
<div id='id-section37'/>
### Page 37:
------
<div id='id-section38'/>
### Page 38:
------
<div id='id-section39'/>
### Page 39:
------
<div id='id-section40'/>
### Page 40:
------
<div id='id-section41'/>
### Page 41:
------
<div id='id-section42'/>
### Page 42:
------
<div id='id-section43'/>
### Page 43:
------
<div id='id-section44'/>
### Page 44:
------
<div id='id-section45'/>
### Page 45:
------
<div id='id-section46'/>
### Page 46:
------
<div id='id-section47'/>
### Page 47:
------
<div id='id-section48'/>
### Page 48:
------
<div id='id-section49'/>
### Page 49:
------
<div id='id-section50'/>
### Page 50:
------
<div id='id-section51'/>
### Page 51:
------
<div id='id-section52'/>
### Page 52:
------
<div id='id-section53'/>
### Page 53:
------
<div id='id-section54'/>
### Page 54:
------
<div id='id-section55'/>
### Page 55:
------
<div id='id-section56'/>
### Page 56:
------
<div id='id-section57'/>
### Page 57:
------
<div id='id-section58'/>
### Page 58:
------
<div id='id-section59'/>
### Page 59:
------
<div id='id-section60'/>
### Page 60:

------